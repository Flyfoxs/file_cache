{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Case\n",
    "- This is used to cache the Dataframe result, even there are multiply Dataframe, which can help to reduce the huge time in feature engineering\n",
    "- It also support to log the function time cost and parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "pip install file_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-25 22:40:42,026 util_log.py[61] DEBUG Start the program at:LALI2-M-G0MD, 127.0.0.1, with:Load module\n",
      "2018-12-25 22:40:42,029 util_log.py[41] INFO Begin:test_cache_normal(1 paras) with:['Felix'], []\n",
      "2018-12-25 22:40:42,178 cache.py[29] DEBUG try to read cache from file:./cache/test_cache_normal=Felix=.h5, (h5, key:['/df_0'])\n",
      "2018-12-25 22:40:42,189 util_log.py[49] INFO Cost:   0.16 sec:'test_cache_normal'(1 paras)(['Felix'], []), return:DataFrame, end \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  0  1  2  3  4\n",
       "1  5  6  7  8  9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  file_cache.cache import file_cache\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "@file_cache()\n",
    "def test_cache_normal(name):\n",
    "    import time\n",
    "    import numpy  as np\n",
    "    time.sleep(3)\n",
    "    return pd.DataFrame(data= np.arange(0,10).reshape(2,5))\n",
    "\n",
    "normal_df = test_cache_normal('Felix')\n",
    "normal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return mulpiple DF with tuple\n",
    "Support to cache multiple DF with tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-25 22:40:42,227 util_log.py[41] INFO Begin:test_cache_tuple(1 paras) with:['Felix2'], []\n",
      "2018-12-25 22:40:42,252 cache.py[29] DEBUG try to read cache from file:./cache/test_cache_tuple=Felix2=.h5, (h5, key:['/df_0', '/df_1'])\n",
      "2018-12-25 22:40:42,273 util_log.py[49] INFO Cost:   0.05 sec:'test_cache_tuple'(1 paras)(['Felix2'], []), return:tuple, end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   5   6   7   8   9\n",
      "1  10  11  12  13  14 \n",
      "\n",
      "    0   1   2   3   4\n",
      "0  20  21  22  23  24\n",
      "1  25  26  27  28  29\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache()\n",
    "@file_cache()\n",
    "def test_cache_tuple(name):\n",
    "    time.sleep(3)\n",
    "    df0 = pd.DataFrame(data= np.arange(5,15).reshape(2,5))\n",
    "    df1 = pd.DataFrame(data= np.arange(20,30).reshape(2,5))\n",
    "    return df0, df1\n",
    "\n",
    "df0, df1 = test_cache_tuple('Felix2')\n",
    "print(df0 , '\\n')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the input paras can not be cached\n",
    "If the input is DF or cannot be hashed, ignore the cache, run the function directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-25 22:40:42,302 util_log.py[41] INFO Begin:test_cache_ignore(1 paras) with:['DataFrame'], []\n",
      "2018-12-25 22:40:42,307 cache.py[112] DEBUG There is DataFrame in the args\n",
      "2018-12-25 22:40:42,309 cache.py[94] WARNING Don not support cache for fn:test_cache_ignore, para:DataFrame, kw:{}\n",
      "2018-12-25 22:40:42,312 util_log.py[49] INFO Cost:   0.01 sec:'test_cache_ignore'(1 paras)(['DataFrame'], []), return:DataFrame, end \n"
     ]
    }
   ],
   "source": [
    "@file_cache()\n",
    "def test_cache_ignore(name):\n",
    "    df0 = pd.DataFrame(data= np.arange(5,15).reshape(2,5))\n",
    "    return df0\n",
    "\n",
    "df = pd.DataFrame(data= np.arange(5,15).reshape(2,5))\n",
    "ignore = test_cache_ignore(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log the function time and parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-26 11:08:52,662 util_log.py[61] DEBUG Start the program at:LALI2-M-G0MD, 127.0.0.1, with:Load module\n",
      "2018-12-26 11:08:52,665 util_log.py[41] INFO log_time begin with(1 paras) :['hello'], []\n",
      "2018-12-26 11:08:52,667 util_log.py[49] INFO log_time cost:   0.00 sec:(1 paras)(['hello'], []), return:hello msg, end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello msg\n"
     ]
    }
   ],
   "source": [
    "from file_cache.utils.util_log import *\n",
    "@timed()\n",
    "def log_time(arg):\n",
    "    return f'{arg} msg'\n",
    "\n",
    "print(log_time(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Not only support DataFrame, but also support Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-26 11:16:24,937 util_log.py[41] INFO get_train_data begin with(0 paras) :[], []\n",
      "2018-12-26 11:16:24,941 cache.py[38] DEBUG Can not find cache from file:./cache/get_train_data==.h5\n",
      "2018-12-26 11:16:24,949 cache.py[62] DEBUG ====Write 506 records to File#./cache/get_train_data==.h5, with:df_0\n",
      "2018-12-26 11:16:25,142 cache.py[62] DEBUG ====Write 506 records to File#./cache/get_train_data==.h5, with:df_1\n",
      "2018-12-26 11:16:25,151 util_log.py[49] INFO get_train_data cost:   0.21 sec:(0 paras)([], []), return:tuple, end \n",
      "2018-12-26 11:16:25,156 util_log.py[41] INFO get_train_data begin with(0 paras) :[], []\n",
      "2018-12-26 11:16:25,170 cache.py[29] DEBUG try to read cache from file:./cache/get_train_data==.h5, (h5, key:['/df_0', '/df_1'])\n",
      "2018-12-26 11:16:25,186 util_log.py[49] INFO get_train_data cost:   0.03 sec:(0 paras)([], []), return:tuple, end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "from  file_cache.cache import file_cache\n",
    "@file_cache()\n",
    "def get_train_data():\n",
    "    from sklearn import datasets\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data = datasets.load_boston()\n",
    "    df = pd.DataFrame( data.data , columns=data.feature_names)\n",
    "    df['target'] = data.target\n",
    "    df.head()\n",
    "    return df, df['target']\n",
    "\n",
    "df, series = get_train_data()\n",
    "print(type(df), type(series))\n",
    "\n",
    "df, series = get_train_data()\n",
    "print(type(df), type(series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
