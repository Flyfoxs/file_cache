{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Case(AOP base on decorator)\n",
    "- This is used to cache the Dataframe result, even there are multiply Dataframe, which can help to reduce the huge time in feature engineering\n",
    "- It also support to log the function time cost and parameters\n",
    "- It will create a folder **cache** in your working dir automaticlly, which is used to cache the result in this folder\n",
    "\n",
    "\n",
    "You can also get the demo from [Here](https://github.com/Flyfoxs/file_cache/blob/master/demo.ipynb), it more easy to understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "pip install file_cache\n",
    "\n",
    "pip install --user file_cache (install without root privilege)\n",
    "\n",
    "[pypi Link](https://pypi.org/project/file-cache/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  0  1  2  3  4\n",
       "1  5  6  7  8  9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  file_cache.utils.cache import file_cache\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "@file_cache()\n",
    "def test_cache_normal(name):\n",
    "    import time\n",
    "    import numpy  as np\n",
    "    time.sleep(3)\n",
    "    return pd.DataFrame(data= np.arange(0,10).reshape(2,5))\n",
    "\n",
    "normal_df = test_cache_normal('Felix')\n",
    "normal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return mulpiple DF with tuple\n",
    "Support to cache multiple DF with tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   5   6   7   8   9\n",
      "1  10  11  12  13  14 \n",
      "\n",
      "    0   1   2   3   4\n",
      "0  20  21  22  23  24\n",
      "1  25  26  27  28  29\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache()\n",
    "@file_cache()\n",
    "def test_cache_tuple(name):\n",
    "    time.sleep(3)\n",
    "    df0 = pd.DataFrame(data= np.arange(5,15).reshape(2,5))\n",
    "    df1 = pd.DataFrame(data= np.arange(20,30).reshape(2,5))\n",
    "    return df0, df1\n",
    "\n",
    "df0, df1 = test_cache_tuple('Felix2')\n",
    "print(df0 , '\\n')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the input paras, if it can not be cached\n",
    "If the input is DF or cannot be hashed, ignore the cache, run the function directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 22:43:29,903 cache.py[91] WARNING Do not support cache for fn:test_cache_ignore, para:DataFrame, kw:{}\n"
     ]
    }
   ],
   "source": [
    "@file_cache()\n",
    "def test_cache_ignore(name):\n",
    "    df0 = pd.DataFrame(data= np.arange(5,15).reshape(2,5))\n",
    "    return df0\n",
    "\n",
    "df = pd.DataFrame(data= np.arange(5,15).reshape(2,5))\n",
    "ignore = test_cache_ignore(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log the function time and parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'other'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-1245be68d679>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;34mf'{arg} msg'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlog_time\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"hello\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/python_repo/file_cache/file_cache/utils/util_log.py\u001B[0m in \u001B[0;36minner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     77\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0minner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 79\u001B[0;31m             \u001B[0;32mfrom\u001B[0m \u001B[0mother\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mis_mini_args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m             \u001B[0;34m\"\"\"print simple object directly and customize complex object\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'other'"
     ]
    }
   ],
   "source": [
    "from file_cache.utils.util_log import *\n",
    "@timed()\n",
    "def log_time(arg):\n",
    "    return f'{arg} msg'\n",
    "\n",
    "print(log_time(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Not only support DataFrame, but also support Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  file_cache.cache import file_cache\n",
    "@file_cache()\n",
    "def get_train_data():\n",
    "    from sklearn import datasets\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data = datasets.load_boston()\n",
    "    df = pd.DataFrame( data.data , columns=data.feature_names)\n",
    "    df['target'] = data.target\n",
    "    df.head()\n",
    "    return df, df['target']\n",
    "\n",
    "df, series = get_train_data()\n",
    "print(type(df), type(series))\n",
    "\n",
    "df, series = get_train_data()\n",
    "print(type(df), type(series))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce 70+% memory cost for pandas object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_cache.utils.reduce_mem import reduce_mem\n",
    "from file_cache.utils.util_log import logger\n",
    "@reduce_mem()\n",
    "def get_train_data():\n",
    "    from sklearn import datasets\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data = datasets.load_boston()\n",
    "    df = pd.DataFrame( data.data , columns=data.feature_names)\n",
    "    df.head()\n",
    "    print(f'Original type:\\n{df.dtypes}')\n",
    "    return df\n",
    "\n",
    "df = get_train_data()\n",
    "\n",
    "print(f'New type:\\n{df.dtypes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}